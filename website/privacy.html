<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="UTF-8" />
  <meta name="viewport" content="width=device-width, initial-scale=1.0" />
  <title>Privacy &amp; Security – AI‑Driven Economic Insights</title>
  <link rel="stylesheet" href="style.css" />
</head>
<body>
  <header>
    <h1>Privacy &amp; Security</h1>
    <p class="tagline">Protecting data, identity and trust in an AI world</p>
  </header>
  <nav id="nav-buttons">
    <div class="button-row">
      <button class="nav-button" onclick="location.href='economy.html'">
        <img src="images/economy_icon.png" alt="Economy icon" class="nav-icon" />
        <span class="label">Economy &amp; Policy</span>
      </button>
      <button class="nav-button" onclick="location.href='technology.html'">
        <img src="images/ai_icon.png" alt="AI icon" class="nav-icon" />
        <span class="label">AI &amp; Technology</span>
      </button>
      <button class="nav-button" onclick="location.href='society.html'">
        <img src="images/society_icon.png" alt="Society icon" class="nav-icon" />
        <span class="label">Society &amp; Mental Health</span>
      </button>
      <button class="nav-button" onclick="location.href='privacy.html'">
        <img src="images/privacy_icon.png" alt="Privacy icon" class="nav-icon" />
        <span class="label">Privacy &amp; Security</span>
      </button>
    </div>
    <div class="cta-container">
      <button class="cta-button" onclick="location.href='action.html'">
        <img src="images/action_icon.png" alt="Action icon" class="nav-icon" />
        <span class="label">What We Can Do Now</span>
      </button>
    </div>
  </nav>
  <main>
    <section class="content-section">
      <h2>Threats &amp; Misinformation</h2>
      <p>AI makes it easier to clone voices, fabricate videos and spin up scam chatbots.  <strong>Voice‑cloning scams</strong> already target 28 % of people【877154183811370†L142-L160】.  Fraudsters can clone a voice from seconds of audio, then call loved ones requesting emergency funds.  Malicious chatbots harvest payment or personal data, while generative AI can doctor speeches or create deepfakes that undermine elections【877154183811370†L142-L154】.  As agentic systems mature, autonomous fraud bots could scale scams dramatically【877154183811370†L156-L160】.</p>
      <p>Traditional two‑factor authentication methods like facial or voice recognition may become less reliable【877154183811370†L160-L162】.  Privacy threats also arise from mass data collection, surveillance and predictive profiling.  New regulations are emerging to address AI governance and protect personal data【240192331752712†L493-L495】.</p>
    </section>
    <section class="content-section">
      <h2>Security Best Practices</h2>
      <p>Individuals and organisations must adopt robust security habits.  To combat deepfakes and scam messages:</p>
      <ul>
        <li><strong>Spot manipulation:</strong> Look for unnatural eye movements, mismatched lighting and inconsistent details in media.</li>
        <li><strong>Use code words:</strong> Establish safe phrases with friends and family to verify identity during emergencies.</li>
        <li><strong>Verify requests:</strong> Always call back using a trusted number before sending money or sensitive information.</li>
        <li><strong>Secure your accounts:</strong> Employ hardware security keys or app‑based authenticators rather than voice or face recognition.</li>
        <li><strong>Stay informed:</strong> Keep up to date with evolving scam tactics and report suspicious activity.</li>
      </ul>
    </section>
    <section class="content-section">
      <h2>Data Privacy &amp; Ethics</h2>
      <p>AI systems rely on vast datasets, which can include personal and sensitive information.  Responsible use requires transparency, consent and adherence to regulations.  Policymakers worldwide are accelerating AI governance【240192331752712†L493-L495】, issuing new rules and guidelines to protect privacy and prevent abuse.  Ethics frameworks emphasise fairness, accountability and human oversight.</p>
      <p>When using AI tools, minimise data collection to what is necessary, anonymise sensitive fields and delete data once it is no longer needed.  Organisations should conduct regular audits to identify biases and vulnerabilities.  Empowering users through clear privacy notices and control over their data builds trust.</p>
    </section>
  </main>
  <footer>
    <p>&copy; 2025 The Swarm Collective. All rights reserved.</p>
  </footer>
  <script src="script.js"></script>
</body>
</html>